{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    # Convert mpimg color space into 1-channel grayscale\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size=5):\n",
    "    # Apply Gaussian blur with default kernel size\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    # Canny edge detection\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_roi(img):\n",
    "    r, c, _ = image.shape\n",
    "    vertices = np.array([[\n",
    "        (20, r),                       # lower left\n",
    "        (c // 2 - 20, r // 2 + 50),    # upper left\n",
    "        (c // 2 + 20, r // 2 + 50),    # upper right\n",
    "        (c - 20, r),                   # lower right\n",
    "    ]], dtype=np.int32)\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked = cv2.bitwise_and(img, mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img):\n",
    "    # Distance resolution of the Hough grid (in pixels)\n",
    "    rho = 2\n",
    "    # Angular resolution of the Hough grid (in radians)\n",
    "    theta = np.pi / 180\n",
    "    # Min. # of votes required for a line\n",
    "    threshold = 5\n",
    "    # Min. # of pixels required for a line\n",
    "    min_line_len = 20\n",
    "    # Maximum gap between connectable line segments\n",
    "    max_line_gap = 40\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(img):\n",
    "    # Obtain grayscale image\n",
    "    gray = grayscale(img)\n",
    "    # Apply Gaussian blur filter\n",
    "    blurred = gaussian_blur(gray, 3)\n",
    "    # Detect Canny edges\n",
    "    edges = canny(blurred, 50, 200)\n",
    "    # Mask region of interest\n",
    "    roi = polygon_roi(edges)\n",
    "    # Detect Hough lines\n",
    "    lines = hough_lines(roi)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lines(lines, min_angle, max_angle, min_x, max_x):\n",
    "    # Calculate tangent for each angle\n",
    "    min_gradient = np.tan(np.radians(min_angle))\n",
    "    max_gradient = np.tan(np.radians(max_angle))\n",
    "    selected = []\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            # First we check the position of the line\n",
    "            if min(x1, x2) < min_x or max(x1, x2) > max_x:\n",
    "                continue\n",
    "            # Vertical lines are not likely to be lane lines\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            # We subtract y2 from y1 since y-axis is upside down\n",
    "            m = (y1 - y2) / (x2 - x1)\n",
    "            # For those selected lines, keep the following:\n",
    "            # (1) gradient, (2) y-intercept, (3) segnemtn length,\n",
    "            if min_gradient <= m <= max_gradient:\n",
    "                selected.append(line)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_lines(lines):\n",
    "    gradients, intercepts, weights = [], [], []\n",
    "    min_y, max_y = 0, 560\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            # Keep min & max y values\n",
    "            min_y = min(y1, y2) if min_y == 0 or min(y1, y2) < min_y else min_y\n",
    "            max_y = max(y1, y2) if max(y1, y2) > max_y else max_y\n",
    "            m = (y2 - y1) / (x2 - x1)\n",
    "            b = y1 - m * x1\n",
    "            # Use each line's length as its weight in averaging\n",
    "            l = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "            gradients.append(m)\n",
    "            intercepts.append(b)\n",
    "            weights.append(l)\n",
    "    # Now we compute weighted (based on line length) average of the\n",
    "    # gradient and y-intercept\n",
    "    g, i, w = np.array(gradients), np.array(intercepts), np.array(weights)\n",
    "    avg_m = np.average(g, weights=w)\n",
    "    avg_b = np.average(i, weights=w)\n",
    "    # Calculate low & high endpoints\n",
    "    x1 = int((max_y - avg_b) / avg_m)\n",
    "    x2 = int((min_y - avg_b) / avg_m)\n",
    "    return x1, max_y, x2, min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, c=(255, 0, 0), t=2):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), c, t)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    lines = detect_lines(img)\n",
    "    # print(\"# of found lines: \", len(lines))\n",
    "    left_candidates = select_lines(lines, 30, 45, 0, 480)\n",
    "    # print(\"# of left lane line candidates: \", len(left_candidates))\n",
    "    right_candidates = select_lines(lines, -45, -30, 480, 960)\n",
    "    # print(\"# of right lane line candidates: \", len(right_candidates))\n",
    "\n",
    "    line_img = np.zeros_like(img)\n",
    "    # line_img = draw_lines(line_img, left_candidates, c=(0, 255, 0))\n",
    "    # line_img = draw_lines(line_img, right_candidates, c=(255, 255, 0))\n",
    "    if len(left_candidates) > 0:\n",
    "        left_lane_line = aggregate_lines(left_candidates)\n",
    "        line_img = draw_lines(line_img, [(left_lane_line, )], c=(255, 0, 0), t=10)\n",
    "    if len(right_candidates) > 0:\n",
    "        right_lane_line = aggregate_lines(right_candidates)\n",
    "        line_img = draw_lines(line_img, [(right_lane_line, )], c=(0, 0, 255), t=10)\n",
    "    annotated = weighted_img(line_img, img)\n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = os.listdir(\"test_images\")\n",
    "for filename in filenames:\n",
    "    pathname = os.path.join(os.getcwd(), \"test_images\", filename)\n",
    "    # Read image file\n",
    "    image = mpimg.imread(pathname)\n",
    "    lane_line_detection = process_image(image)\n",
    "    cv2_image = cv2.cvtColor(lane_line_detection, cv2.COLOR_RGB2BGR)\n",
    "    output_pathname = os.path.join(os.getcwd(), \"test_images_output\", filename)\n",
    "    cv2.imwrite(output_pathname, cv2_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /src/test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:05<00:00, 36.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 2.22 s, sys: 284 ms, total: 2.51 s\n",
      "Wall time: 6.82 s\n",
      "[MoviePy] >>>> Building video /src/test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:15<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 6.18 s, sys: 610 ms, total: 6.79 s\n",
      "Wall time: 17.5 s\n",
      "[MoviePy] >>>> Building video /src/test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:22<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 8.03 s, sys: 916 ms, total: 8.95 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "filenames = os.listdir(\"test_videos\")\n",
    "for filename in filenames:\n",
    "    pathname = os.path.join(os.getcwd(), \"test_videos\", filename)\n",
    "    output_pathname = os.path.join(os.getcwd(), \"test_videos_output\", filename)\n",
    "    clip = VideoFileClip(pathname)\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    %time output_clip.write_videofile(output_pathname, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
