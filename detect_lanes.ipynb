{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    # Convert mpimg color space into 1-channel grayscale\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size=5):\n",
    "    # Apply Gaussian blur with default kernel size\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    # Canny edge detection\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_roi(img):\n",
    "    if len(img.shape) == 3:\n",
    "        r, c, _ = img.shape\n",
    "        color_mask = (255, 255, 255)\n",
    "    else:\n",
    "        r, c = img.shape\n",
    "        color_mask = 255\n",
    "    offset_lb = c // 10\n",
    "    offset_rb = c // 20\n",
    "    offset_lt = c // 20\n",
    "    offset_rt = c // 20\n",
    "    offset_bottom = 0\n",
    "    offset_top = r // 11\n",
    "    vertices = np.array([[\n",
    "        (0 + offset_lb, r + offset_bottom),           # bottom left\n",
    "        (c // 2 - offset_lt, r // 2 + offset_top),    # top left\n",
    "        (c // 2 + offset_rt, r // 2 + offset_top),    # top right\n",
    "        (c - offset_rb, r + offset_bottom),           # bottom right\n",
    "    ]], dtype=np.int32)\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.fillPoly(mask, vertices, color_mask)\n",
    "    masked = cv2.bitwise_and(img, mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img):\n",
    "    # Distance resolution of the Hough grid (in pixels)\n",
    "    rho = 2\n",
    "    # Angular resolution of the Hough grid (in radians)\n",
    "    theta = np.pi / 180\n",
    "    # Min. # of votes required for a line\n",
    "    threshold = 5\n",
    "    # Min. # of pixels required for a line\n",
    "    min_line_len = 20\n",
    "    # Maximum gap between connectable line segments\n",
    "    max_line_gap = 40\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Line Detection\n",
    "\n",
    "A 5-stage pipeline:\n",
    "1. Convert to grayscale image\n",
    "1. Apply Gaussian Blur\n",
    "1. Detect Canny edges\n",
    "1. Masking for ROI extraction\n",
    "1. Detect Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(img):\n",
    "    # Obtain grayscale image\n",
    "    gray = grayscale(img)\n",
    "    # Apply Gaussian blur filter\n",
    "    blurred = gaussian_blur(gray, 3)\n",
    "    # Detect Canny edges\n",
    "    edges = canny(blurred, 50, 200)\n",
    "    # Mask region of interest\n",
    "    roi = polygon_roi(edges)\n",
    "    # Detect Hough lines\n",
    "    lines = hough_lines(roi)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select candidates for lane lines\n",
    "\n",
    "Given a list of lines, select among them those with\n",
    "* both the endpoints within the x range of [`min_x`, `max_x`], and\n",
    "* angle to the X-axis within the range [`min_angle`, `max_angle`].\n",
    "This function is used for collecting line segments that are possibly left and right lane lines on the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lines(lines, min_angle, max_angle, min_x, max_x):\n",
    "    # Calculate tangent for each angle\n",
    "    min_gradient = np.tan(np.radians(min_angle))\n",
    "    max_gradient = np.tan(np.radians(max_angle))\n",
    "    selected = []\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            # First we check the position of the line\n",
    "            if min(x1, x2) < min_x or max(x1, x2) > max_x:\n",
    "                continue\n",
    "            # Vertical lines are not likely to be lane lines\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            # We subtract y2 from y1 since y-axis is upside down\n",
    "            m = (y1 - y2) / (x2 - x1)\n",
    "            # For those selected lines, keep the following:\n",
    "            # (1) gradient, (2) y-intercept, (3) segnemtn length,\n",
    "            if min_gradient <= m <= max_gradient:\n",
    "                selected.append(line)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Multiple (similarly oriented) Lines\n",
    "\n",
    "1. Calculate parameters of each line segment (gradient and y-intercept)\n",
    "1. Calculate weight of each segment (based on its length)\n",
    "1. Weighted averages for gradient and y-intercept --> this is the aggregated line\n",
    "1. Provide endpoints, with one around the top (minimum y value) and the other around the bottom (a large value used so that the line extends across the lower border of the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_lines(lines, max_y, min_y):\n",
    "    gradients, intercepts, weights = [], [], []\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            m = (y2 - y1) / (x2 - x1)\n",
    "            b = y1 - m * x1\n",
    "            # Use each line's length as its weight in averaging\n",
    "            l = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "            gradients.append(m)\n",
    "            intercepts.append(b)\n",
    "            weights.append(l)\n",
    "    # Now we compute weighted (based on line length) average of the\n",
    "    # gradient and y-intercept\n",
    "    g, i, w = np.array(gradients), np.array(intercepts), np.array(weights)\n",
    "    avg_m = np.average(g, weights=w)\n",
    "    avg_b = np.average(i, weights=w)\n",
    "    # Calculate low & high endpoints\n",
    "    x1 = int((max_y - avg_b) / avg_m)\n",
    "    x2 = int((min_y - avg_b) / avg_m)\n",
    "    return x1, max_y, x2, min_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, c=(255, 0, 0), t=2):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), c, t)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processor\n",
    "\n",
    "Given an image, detect lane lines in it and annotate the left lane line with red and the right one with blue; return the annotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    r = img.shape[0]\n",
    "    c = img.shape[1]\n",
    "    lines = detect_lines(img)\n",
    "    # print(\"# of found lines: \", len(lines))\n",
    "    left_candidates = select_lines(lines, 30, 45, 0, c // 2)\n",
    "    # print(\"# of left lane line candidates: \", len(left_candidates))\n",
    "    right_candidates = select_lines(lines, -45, -30, c // 2, c)\n",
    "    # print(\"# of right lane line candidates: \", len(right_candidates))\n",
    "\n",
    "    line_img = np.zeros_like(img)\n",
    "    # line_img = draw_lines(line_img, left_candidates, c=(0, 255, 0))\n",
    "    # line_img = draw_lines(line_img, right_candidates, c=(255, 255, 0))\n",
    "    if len(left_candidates) > 0:\n",
    "        left_lane_line = aggregate_lines(left_candidates, r, 3 * r // 5)\n",
    "        line_img = draw_lines(line_img, [(left_lane_line, )], c=(255, 0, 0), t=10)\n",
    "    if len(right_candidates) > 0:\n",
    "        right_lane_line = aggregate_lines(right_candidates, r, 3 * r // 5)\n",
    "        line_img = draw_lines(line_img, [(right_lane_line, )], c=(0, 0, 255), t=10)\n",
    "    annotated = weighted_img(line_img, img)\n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on Still Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = os.listdir(\"test_images\")\n",
    "for filename in filenames:\n",
    "    pathname = os.path.join(os.getcwd(), \"test_images\", filename)\n",
    "    # Read image file\n",
    "    image = mpimg.imread(pathname)\n",
    "    lane_line_detection = process_image(image)\n",
    "    cv2_image = cv2.cvtColor(lane_line_detection, cv2.COLOR_RGB2BGR)\n",
    "    output_pathname = os.path.join(os.getcwd(), \"test_images_output\", filename)\n",
    "    cv2.imwrite(output_pathname, cv2_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on Sample Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /src/test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:06<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 2.31 s, sys: 304 ms, total: 2.61 s\n",
      "Wall time: 7.27 s\n",
      "[MoviePy] >>>> Building video /src/test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:17<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 6.15 s, sys: 804 ms, total: 6.95 s\n",
      "Wall time: 19.5 s\n",
      "[MoviePy] >>>> Building video /src/test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video /src/test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:21<00:00, 32.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /src/test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 7.51 s, sys: 893 ms, total: 8.4 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "filenames = os.listdir(\"test_videos\")\n",
    "for filename in filenames:\n",
    "    pathname = os.path.join(os.getcwd(), \"test_videos\", filename)\n",
    "    output_pathname = os.path.join(os.getcwd(), \"test_videos_output\", filename)\n",
    "    clip = VideoFileClip(pathname)\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    %time output_clip.write_videofile(output_pathname, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
